{
    "cells":  [
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {
                                       "colab":  {

                                                 },
                                       "id":  "Uo_nP8CmfVmQ"
                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "!pip uninstall interpret interpret-community -y\n",
                                     "!pip install transformers lime datasets plotly\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {
                                       "id":  "lime_intro"
                                   },
                      "source":  [
                                     "## LIME-based explanations for transformer text models\n",
                                     "We treat the Hugging Face pipeline as a black-box classifier and use LIME to perturb the input text to estimate which tokens push the model toward each label.\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {
                                       "id":  "lime_setup"
                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from transformers import pipeline\n",
                                     "from lime.lime_text import LimeTextExplainer\n",
                                     "import numpy as np\n",
                                     "np.random.seed(42)\n",
                                     "\n",
                                     "# Use a pretrained sentiment analysis model as an example black-box classifier\n",
                                     "classifier = pipeline(\u0027text-classification\u0027, model=\u0027distilbert-base-uncased-finetuned-sst-2-english\u0027, return_all_scores=True)\n",
                                     "\n",
                                     "# Identify the class labels that the pipeline returns\n",
                                     "_sample_scores = classifier(\u0027This placeholder call collects label names.\u0027, truncation=True)[0]\n",
                                     "class_names = [entry[\u0027label\u0027] for entry in _sample_scores]\n",
                                     "explainer = LimeTextExplainer(class_names=class_names)\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {
                                       "id":  "lime_helpers"
                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from IPython.display import display, HTML\n",
                                     "from pathlib import Path\n",
                                     "import matplotlib.pyplot as plt\n",
                                     "\n",
                                     "def predict_proba(texts):\n",
                                     "    \"\"\"Wrap the Hugging Face pipeline so LIME can query class probabilities.\"\"\"\n",
                                     "    outputs = classifier(texts, truncation=True)\n",
                                     "    return np.array([[entry[\u0027score\u0027] for entry in sample] for sample in outputs], dtype=float)\n",
                                     "\n",
                                     "def explain_text(text, num_features=10, show_html=False, show_figure=True, save_html_path=None):\n",
                                     "    \"\"\"Run LIME on a single text example, print weights, and render static and/or interactive views.\"\"\"\n",
                                     "    explanation = explainer.explain_instance(text, predict_proba, num_features=num_features)\n",
                                     "    probabilities = predict_proba([text])[0]\n",
                                     "    top_label = class_names[int(np.argmax(probabilities))]\n",
                                     "    print(f\u0027Model prediction: {top_label} (confidence={probabilities.max():.3f})\u0027)\n",
                                     "    print(\u0027\\nToken contributions (positive pushes prediction up, negative down):\u0027)\n",
                                     "    for token, weight in explanation.as_list():\n",
                                     "        print(f\u0027{token}: {weight:+.3f}\u0027)\n",
                                     "\n",
                                     "    if show_figure:\n",
                                     "        fig = explanation.as_pyplot_figure()\n",
                                     "        fig.tight_layout()\n",
                                     "        plt.show()\n",
                                     "    else:\n",
                                     "        fig = None\n",
                                     "\n",
                                     "    if show_html or save_html_path:\n",
                                     "        html = explanation.as_html()\n",
                                     "        if show_html:\n",
                                     "            display(HTML(html))\n",
                                     "        if save_html_path:\n",
                                     "            Path(save_html_path).write_text(html, encoding=\u0027utf-8\u0027)\n",
                                     "            print(f\u0027Saved interactive HTML to {Path(save_html_path).resolve()}\u0027)\n",
                                     "\n",
                                     "    return explanation, fig\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {
                                       "id":  "lime_demo"
                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "sample_text = \u0027The movie had gorgeous visuals but the storyline fell flat and predictable.\u0027\n",
                                     "lime_explanation, lime_fig = explain_text(\n",
                                     "    sample_text,\n",
                                     "    num_features=10,\n",
                                     "    show_html=False,\n",
                                     "    show_figure=True,\n",
                                     "    save_html_path=\u0027lime_explanation.html\u0027\n",
                                     ")\n"
                                 ]
                  }
              ],
    "metadata":  {
                     "accelerator":  "GPU",
                     "colab":  {
                                   "gpuType":  "T4",
                                   "provenance":  [

                                                  ],
                                   "toc_visible":  true
                               },
                     "kernelspec":  {
                                        "display_name":  "Python 3",
                                        "name":  "python3"
                                    },
                     "language_info":  {
                                           "name":  "python"
                                       },
                     "widgets":  {
                                     "state":  {

                                               },
                                     "version_major":  2,
                                     "version_minor":  0
                                 }
                 },
    "nbformat":  4,
    "nbformat_minor":  0
}
