{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "id": "Uo_nP8CmfVmQ"
      },
      "outputs": [],
      "source": [
        "!pip uninstall interpret interpret-community -y\n",
        "!pip install transformers lime datasets plotly\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lime_intro"
      },
      "source": [
        "## LIME-based explanations for transformer text models\n",
        "We treat the Hugging Face pipeline as a black-box classifier and use LIME to perturb the input text to estimate which tokens push the model toward each label.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lime_setup"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "# Use a pretrained sentiment analysis model as an example black-box classifier\n",
        "classifier = pipeline('text-classification', model='distilbert-base-uncased-finetuned-sst-2-english', return_all_scores=True)\n",
        "\n",
        "# Identify the class labels that the pipeline returns\n",
        "_sample_scores = classifier('This placeholder call collects label names.', truncation=True)[0]\n",
        "class_names = [entry['label'] for entry in _sample_scores]\n",
        "explainer = LimeTextExplainer(class_names=class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lime_helpers"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def predict_proba(texts):\n",
        "    \"\"\"Wrap the Hugging Face pipeline so LIME can query class probabilities.\"\"\"\n",
        "    outputs = classifier(texts, truncation=True)\n",
        "    return np.array([[entry['score'] for entry in sample] for sample in outputs], dtype=float)\n",
        "\n",
        "def explain_text(text, num_features=10, show_html=False, show_figure=True, save_html_path=None):\n",
        "    \"\"\"Run LIME on a single text example, print weights, and render static and/or interactive views.\"\"\"\n",
        "    explanation = explainer.explain_instance(text, predict_proba, num_features=num_features)\n",
        "    probabilities = predict_proba([text])[0]\n",
        "    top_label = class_names[int(np.argmax(probabilities))]\n",
        "    print(f'Model prediction: {top_label} (confidence={probabilities.max():.3f})')\n",
        "    print('\\nToken contributions (positive pushes prediction up, negative down):')\n",
        "    for token, weight in explanation.as_list():\n",
        "        print(f'{token}: {weight:+.3f}')\n",
        "\n",
        "    if show_figure:\n",
        "        fig = explanation.as_pyplot_figure()\n",
        "        fig.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        fig = None\n",
        "\n",
        "    if show_html or save_html_path:\n",
        "        html = explanation.as_html()\n",
        "        if show_html:\n",
        "            display(HTML(html))\n",
        "        if save_html_path:\n",
        "            Path(save_html_path).write_text(html, encoding='utf-8')\n",
        "            print(f'Saved interactive HTML to {Path(save_html_path).resolve()}')\n",
        "\n",
        "    return explanation, fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lime_demo"
      },
      "outputs": [],
      "source": [
        "sample_text = 'The movie had gorgeous visuals but the storyline fell flat and predictable.'\n",
        "lime_explanation, lime_fig = explain_text(\n",
        "    sample_text,\n",
        "    num_features=10,\n",
        "    show_html=False,\n",
        "    show_figure=True,\n",
        "    save_html_path='lime_explanation.html'\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "state": {},
      "version_major": 2,
      "version_minor": 0
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
